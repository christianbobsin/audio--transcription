import os
import warnings
import glob
import time
import argparse
import whisper

# ==========================
# ‚öôÔ∏è CONFIGURA√á√ÉO PADR√ÉO
# ==========================

# Valor padr√£o se o usu√°rio N√ÉO passar --device
# Pode ser: "cpu", "cuda" ou "auto"
DEVICE_MODE_DEFAULT = "cpu"

# Pasta onde est√£o os √°udios
# Exemplo Linux:  ~/Downloads/audios
# Exemplo Windows: C:\Users\SeuUsuario\Downloads\audios
DIR_AUDIOS = os.path.expanduser("~/Downloads/audios")

# Modelo do Whisper:
# menores = mais r√°pidos; maiores = melhor qualidade
# op√ß√µes: "tiny", "base", "small", "medium"
MODEL_NAME = "small"

# Extens√µes de √°udio suportadas pelo script
AUDIO_EXTENSIONS = [".ogg", ".mp3", ".wav", ".m4a", ".flac", ".webm", ".mp4"]


# ==========================
# üßæ ARGPARSE (OPCIONAL)
# ==========================

parser = argparse.ArgumentParser(
    description="Transcri√ß√£o em lote de arquivos de √°udio usando Whisper."
)

parser.add_argument(
    "--device",
    choices=["cpu", "cuda", "auto"],
    help=(
        "Dispositivo de execu√ß√£o: "
        "'cpu' for√ßa CPU, "
        "'cuda' tenta usar GPU, "
        "'auto' tenta cuda e cai pra cpu se n√£o tiver."
    ),
)

args = parser.parse_args()
DEVICE_MODE = args.device if args.device is not None else DEVICE_MODE_DEFAULT


# =========================================
# üß† SELE√á√ÉO DE DEVICE (CPU / CUDA / AUTO)
# =========================================

DEVICE = "cpu"  # default

if DEVICE_MODE == "cpu":
    # üñ•Ô∏è Modo CPU expl√≠cito:
    # - Esconde GPU s√≥ para ESTE processo
    # - Suprime warnings gen√©ricos que s√≥ confundem
    os.environ["CUDA_VISIBLE_DEVICES"] = ""
    warnings.filterwarnings("ignore", category=UserWarning)
    print("üñ•Ô∏è  Modo selecionado: CPU (GPU ser√° ignorada para este script).")

elif DEVICE_MODE in ("cuda", "auto"):
    import torch  # s√≥ importa se for realmente considerar CUDA

    if torch.cuda.is_available():
        DEVICE = "cuda"
        print("‚ö°  GPU detectada. Tentando usar CUDA...")
    else:
        DEVICE = "cpu"
        print("üñ•Ô∏è  CUDA n√£o dispon√≠vel, usando CPU.")
else:
    raise SystemExit(f"Valor inv√°lido para DEVICE_MODE: {DEVICE_MODE}")


# ==========================
# üöÄ CARREGA MODELO WHISPER
# ==========================

print(f"Carregando modelo '{MODEL_NAME}' no dispositivo: {DEVICE} ...")
model = whisper.load_model(MODEL_NAME, device=DEVICE)


# ==========================
# üéß PROCURA ARQUIVOS DE √ÅUDIO
# ==========================

files: list[str] = []

for ext in AUDIO_EXTENSIONS:
    pattern = os.path.join(DIR_AUDIOS, f"*{ext}")
    files.extend(glob.glob(pattern))

files = sorted(files)

print(
    f"Encontrei {len(files)} arquivos de √°udio em {DIR_AUDIOS} "
    f"({', '.join(AUDIO_EXTENSIONS)})"
)
if not files:
    raise SystemExit(
        "Nenhum arquivo de √°udio encontrado. "
        "Verifique o caminho da pasta e as extens√µes."
    )


# ==========================
# ‚è±Ô∏è TIMER GLOBAL
# ==========================

start_global = time.time()


# ==========================
# üìù LOOP DE TRANSCRI√á√ÉO
# ==========================

for idx, audio in enumerate(files, start=1):
    print(f"\n[{idx}/{len(files)}] Transcrevendo: {audio}")

    start_file = time.time()

    result = model.transcribe(
        audio,
        language="pt",              # for√ßa PT-BR
        fp16=(DEVICE == "cuda"),    # fp16 s√≥ faz sentido na GPU
    )

    elapsed_file = time.time() - start_file

    txt_path = audio + ".txt"
    with open(txt_path, "w", encoding="utf-8") as out:
        out.write(result["text"])

    print(f"   ‚úÖ Transcri√ß√£o salva em: {txt_path}")
    print(f"   ‚è±Ô∏è Tempo deste arquivo: {elapsed_file:.1f} segundos")

elapsed_global = time.time() - start_global
print(f"\nüéâ Conclu√≠do! Tempo total de processamento: {elapsed_global:.1f} segundos.")
